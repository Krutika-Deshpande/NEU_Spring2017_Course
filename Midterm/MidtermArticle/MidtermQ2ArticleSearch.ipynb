{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article Search API Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "import os\n",
    "nyt_article_key = os.getenv('nyt_article_key')\n",
    "date = 20131201\n",
    "page = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?begin_date=\" + str(date) + \"&end_date=\" + str(date) + \"&page=\" + str(page) + \"&api-key=\" + str(nyt_article_key)\n",
    "response = requests.get(url).json()\n",
    "with open(str(date) + '_article_' + str(page)+ '.json', 'w') as fp:\n",
    "    json.dump(response, fp)\n",
    "    page += 1\n",
    "    date += 1\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "newpath = r'MidtermQ2ArticleSearch' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from collections import Counter\n",
    "rootdir = r'\\Users\\kruts\\MidtermTest'\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for name in files:\n",
    "         if name.endswith((\".json\")):\n",
    "            #print(name)\n",
    "            copy(rootdir +'\\\\'+name, newpath)                 \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "path_to_json = 'MidtermQ2ArticleSearch'\n",
    "path_file= r'ArticleResult'\n",
    "\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "#print (json_files) \n",
    "\n",
    "def ensure_dir(path_file):\n",
    "    \n",
    "    if not os.path.exists(path_file):\n",
    "        os.makedirs(path_file) # creating a directory if it doesnt exists.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "file = \"*.json\"\n",
    "\n",
    "from shutil import copy\n",
    "for js in glob.glob(os.path.join(path_to_json,file)):\n",
    "            json_file_read = json.loads(open(js).read())\n",
    "            for key,value in json_file_read.items():\n",
    "                #print(key)\n",
    "                if key == \"response\": # creation of folders\n",
    "                    docs = value.get('docs')\n",
    "                    for article in docs :\n",
    "                        sect_name = article.get('section_name') #creation of folders on the basis of the section_name\n",
    "                        sect_name = str(sect_name).replace(\"/\",\" \")\n",
    "                        sect_name = str(sect_name).replace(\":\",\" \")\n",
    "                        path = os.path.join(path_file + '\\\\' + str(sect_name))\n",
    "                        ensure_dir(path)\n",
    "                        copy(js,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N.Y. / Region', 'Business Day', 'NYT Now', 'Technology', 'Crosswords & Games', 'Fashion & Style', 'Opinion', 'U.S.'}\n"
     ]
    }
   ],
   "source": [
    "response_data=json_file_read['response']['docs']\n",
    "##print(response_data)\n",
    "dic={}\n",
    "section_name = []\n",
    "for x in response_data:\n",
    "    dic.update(x)\n",
    "    for y in dic:\n",
    "        if y == 'section_name':\n",
    "            section_name.append(dic[y])\n",
    "\n",
    "print(set(section_name[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 types are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('U.S.', 968),\n",
       " ('Paid Death Notices', 801),\n",
       " ('Sports', 666),\n",
       " ('World', 649),\n",
       " ('Opinion', 637)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount={}\n",
    "#updated = {}\n",
    "for word in section_name:\n",
    "    if word not in wordcount:\n",
    "        wordcount[word] = 1\n",
    "    else:\n",
    "        wordcount[word] += 1\n",
    "#updated = wordcount.update((k, v) for k, v in wordcount.items() if v is not 'null')      \n",
    "sorted_words=sorted(wordcount.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 5 types are\")\n",
    "sorted_words[:5]\n",
    "#print(updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
